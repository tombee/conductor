# Getting Started

## Installation

=== "macOS"

    ```bash
    curl -L https://github.com/conductor/conductor/releases/latest/download/conductor-darwin-arm64 -o conductor
    chmod +x conductor
    sudo mv conductor /usr/local/bin/
    ```

=== "Linux"

    ```bash
    curl -L https://github.com/conductor/conductor/releases/latest/download/conductor-linux-amd64 -o conductor
    chmod +x conductor
    sudo mv conductor /usr/local/bin/
    ```

## Provider Setup

Conductor needs an LLM provider to run workflows. Choose your preferred option:

=== "Claude Code"

    If you have [Claude Code](https://claude.ai/claude-code) installed:

    ```bash
    conductor provider add claude-code
    ```

    That's it. Conductor uses your existing Claude Code authentication.

=== "Ollama"

    For local models with [Ollama](https://ollama.com):

    ```bash
    # Start Ollama if not running
    ollama serve

    # Pull a model
    ollama pull qwen3:8b

    # Add the provider
    conductor provider add ollama
    ```

    See the [Ollama guide](./providers/ollama.md) for model recommendations by hardware.

Verify your setup:

```bash
conductor provider test
```

You should see a success message. Now you're ready to run your first workflow.

## First Workflow

Create a file `hello.yaml`:

```yaml
name: hello
steps:
  - id: greet
    type: llm
    prompt: Say hello to the world in a creative way
```

Run it:

```bash
conductor run hello.yaml
```

You should see a creative greeting generated by your configured LLM.

## Next Steps

- [Tutorial](./tutorial/index.md) - Build a complete meal planning workflow
- [Providers](./providers/index.md) - Provider configuration reference
