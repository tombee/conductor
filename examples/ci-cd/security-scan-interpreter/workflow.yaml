name: security-scan-interpreter
description: Interpret security scan results, assess actual risk in context, and prioritize fixes
version: "1.0"

inputs:
  - name: scan_file
    type: string
    description: Path to scan results file (SARIF or JSON)
    required: true

  - name: scan_format
    type: string
    default: "sarif"
    description: Format of scan results (sarif, snyk, trivy)

  - name: deployment_context
    type: string
    default: "public"
    description: Deployment context (internal, public, sensitive)

  - name: slack_channel
    type: string
    description: Slack channel for critical alerts (optional)

steps:
  - id: read_scan
    name: Read Scan Results
    file.read:
      path: "{{.inputs.scan_file}}"

  - id: parse_findings
    name: Parse Findings
    type: llm
    model: fast
    system: |
      Extract security findings from the scan results into a structured format.

      For each finding, extract:
      - id: unique identifier
      - severity: CRITICAL, HIGH, MEDIUM, LOW, or INFO
      - title: short description
      - description: full description
      - location: file path and line number if available
      - cve: CVE ID if available
      - cwe: CWE ID if available

      Return as JSON array.
    prompt: |
      Parse these {{.inputs.scan_format}} scan results and extract all findings:

      ```
      {{.steps.read_scan.content | truncate 15000}}
      ```

      Return a JSON array of findings.

  - id: fetch_context
    name: Fetch Affected Files
    type: llm
    model: fast
    prompt: |
      From these findings, list unique file paths that need context:

      {{.steps.parse_findings.response}}

      Return just file paths, one per line.

  - id: analyze_findings
    name: Analyze Findings in Context
    type: llm
    model: strategic
    system: |
      You are a senior security engineer analyzing vulnerability scan results.

      For each finding, assess:
      1. **Exploitability**: Is this actually exploitable in this codebase?
      2. **Reachability**: Is the vulnerable code path reachable from external input?
      3. **Impact**: What's the real-world impact if exploited?
      4. **Context**: Consider the deployment model ({{.inputs.deployment_context}})

      Reclassify findings:
      - CRITICAL: Actively exploitable, severe impact, fix immediately
      - HIGH: Likely exploitable, significant impact, fix this sprint
      - MEDIUM: Possibly exploitable, moderate impact, fix soon
      - LOW: Unlikely to be exploited, minimal impact, track
      - FALSE_POSITIVE: Not applicable in this context, explain why

      Group related findings (same root cause = one issue).
    prompt: |
      Analyze these security findings in the context of a {{.inputs.deployment_context}} deployment:

      ## Findings
      {{.steps.parse_findings.response}}

      For each finding (or group), provide:

      **Finding:** [title]
      **Original Severity:** [from scanner]
      **Assessed Severity:** [your assessment]
      **Confidence:** [HIGH, MEDIUM, LOW]

      **Analysis:**
      - Exploitability: [assessment]
      - Reachability: [assessment]
      - Impact: [assessment]

      **Recommendation:** [specific fix or mitigation]
      **Effort:** [time estimate]

      Group related findings together. Explain false positives.

  - id: generate_report
    name: Generate Report
    type: llm
    model: balanced
    prompt: |
      Create a security scan report from this analysis:

      {{.steps.analyze_findings.response}}

      Format as Markdown:

      # Security Scan Analysis - [date]

      **Scan:** [type]
      **Context:** {{.inputs.deployment_context}}
      **Total Findings:** X â†’ **Actionable:** Y

      ## Summary
      [1-2 sentence executive summary]

      ## Critical (Fix Immediately)
      [findings with specific remediation]

      ## High (Fix This Sprint)
      [findings]

      ## Medium/Low (Track)
      [brief list]

      ## False Positives (No Action)
      [findings with reasoning]

      ## Recommendations
      [prioritized action items]

  - id: alert_critical
    name: Alert on Critical Findings
    condition:
      expression: 'contains(steps.analyze_findings.response, "CRITICAL")'
    slack.post_message:
      channel: "{{.inputs.slack_channel}}"
      text: |
        :rotating_light: *Critical Security Finding Detected*

        A security scan found critical vulnerabilities requiring immediate attention.

        {{.steps.generate_report.response | truncate 1500}}

        Review the full report for remediation steps.

  - id: write_report
    name: Write Report
    file.write:
      path: "security-report.md"
      content: "{{.steps.generate_report.response}}"

outputs:
  - name: report
    type: string
    value: "{{.steps.generate_report.response}}"
    description: Full security analysis report

  - name: has_critical
    type: boolean
    value: "{{contains .steps.analyze_findings.response \"CRITICAL\"}}"
    description: Whether critical findings were detected
