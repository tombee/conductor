name: observability-demo
description: Demonstration of observability connectors for logs, metrics, and events

connectors:
  # Datadog connector for logs, metrics, and events
  datadog:
    from: connectors/datadog
    auth:
      type: bearer
      token: $secret:datadog_api_key
    site: datadoghq.com
    default_tags:
      - "env:production"
      - "team:platform"
      - "workflow:observability-demo"
    default_source: conductor
    default_service: conductor-workflows

  # Splunk HEC connector
  splunk:
    from: connectors/splunk
    base_url: https://splunk.example.com:8088
    auth:
      type: bearer
      token: $secret:splunk_hec_token
    default_index: conductor
    default_source: conductor
    default_sourcetype: conductor:workflow

  # Grafana Loki connector
  loki:
    from: connectors/loki
    base_url: https://loki.example.com:3100
    auth:
      type: bearer
      token: $secret:loki_token
    default_labels:
      app: conductor
      env: production

  # Elasticsearch connector
  elasticsearch:
    from: connectors/elasticsearch
    base_url: https://elasticsearch.example.com:9200
    auth:
      type: basic
      username: $secret:es_username
      password: $secret:es_password
    default_index: conductor-logs

steps:
  # Example 1: Send log to Datadog
  - id: log_to_datadog
    uses: datadog.log
    with:
      message: "Workflow started: observability-demo"
      status: info
      tags:
        - "step:start"
      attributes:
        workflow_id: "{{.workflow.id}}"
        timestamp: "{{.workflow.started_at}}"

  # Example 2: Send metric to Datadog
  - id: metric_to_datadog
    uses: datadog.metric
    with:
      metric: workflow.execution.start
      type: count
      value: 1
      tags:
        - "workflow:{{.workflow.name}}"
        - "status:started"

  # Example 3: Process some data (simulated)
  - id: process_data
    type: shell
    run: |
      echo "Processing data..."
      sleep 2
      echo "Processing complete"

  # Example 4: Send event to Datadog
  - id: event_to_datadog
    uses: datadog.event
    with:
      title: "Workflow Milestone: Data Processing Complete"
      text: |
        The workflow '{{.workflow.name}}' has completed data processing.

        Duration: {{.steps.process_data.duration_ms}}ms
      alert_type: success
      priority: normal
      tags:
        - "workflow:{{.workflow.name}}"
        - "step:{{.steps.process_data.id}}"

  # Example 5: Send log to Splunk
  - id: log_to_splunk
    uses: splunk.log
    with:
      event:
        message: "Data processing completed"
        workflow: "{{.workflow.name}}"
        step_id: "{{.steps.process_data.id}}"
        duration_ms: "{{.steps.process_data.duration_ms}}"
        status: "success"
      sourcetype: conductor:workflow

  # Example 6: Send structured event to Splunk
  - id: event_to_splunk
    uses: splunk.event
    with:
      fields:
        event_type: workflow_milestone
        workflow_name: "{{.workflow.name}}"
        workflow_id: "{{.workflow.id}}"
        step_completed: process_data
        duration_ms: "{{.steps.process_data.duration_ms}}"
        status: success
      index: workflow_events

  # Example 7: Push logs to Loki
  - id: log_to_loki
    uses: loki.push
    with:
      line: "Workflow step completed: process_data, duration: {{.steps.process_data.duration_ms}}ms"
      labels:
        workflow: "{{.workflow.name}}"
        step: "process_data"
        level: info
        status: success

  # Example 8: Batch push logs to Loki
  - id: batch_log_to_loki
    uses: loki.push
    with:
      entries:
        - line: "Step 1: Started data processing"
        - line: "Step 2: Data processing in progress"
        - line: "Step 3: Data processing completed successfully"
      labels:
        workflow: "{{.workflow.name}}"
        batch: "process_steps"
        level: info

  # Example 9: Index document in Elasticsearch
  - id: index_to_elasticsearch
    uses: elasticsearch.index
    with:
      index: "conductor-logs-{{.date}}"
      document:
        workflow_name: "{{.workflow.name}}"
        workflow_id: "{{.workflow.id}}"
        event_type: "workflow_completion"
        step_id: "process_data"
        duration_ms: "{{.steps.process_data.duration_ms}}"
        status: "success"
        message: "Data processing completed successfully"
      refresh: wait_for

  # Example 10: Bulk index to Elasticsearch
  - id: bulk_index_to_elasticsearch
    uses: elasticsearch.bulk
    with:
      index: "conductor-metrics-{{.date}}"
      documents:
        - _id: "metric-start"
          metric_name: "workflow.start"
          metric_value: 1
          workflow: "{{.workflow.name}}"
        - _id: "metric-duration"
          metric_name: "workflow.step.duration"
          metric_value: "{{.steps.process_data.duration_ms}}"
          step_id: "process_data"
        - _id: "metric-success"
          metric_name: "workflow.step.success"
          metric_value: 1
          step_id: "process_data"
      refresh: true

  # Final metric: Workflow complete
  - id: final_metric
    uses: datadog.metric
    with:
      series:
        - metric: workflow.execution.complete
          type: count
          value: 1
          tags:
            - "workflow:{{.workflow.name}}"
            - "status:success"
        - metric: workflow.execution.duration
          type: gauge
          value: "{{.workflow.duration_ms}}"
          unit: milliseconds
          tags:
            - "workflow:{{.workflow.name}}"
